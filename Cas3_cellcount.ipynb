{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sLlmkpZiL7q"
      },
      "outputs": [],
      "source": [
        "#Caspase/DAPI overaly Code\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KDTree\n",
        "from google.colab import files\n",
        "import io, sys\n",
        "\n",
        "# ---------- small helper ----------\n",
        "def prompt_yn(msg=\"Continue? [y/n]: \"):\n",
        "    while True:\n",
        "        a = input(msg).strip().lower()\n",
        "        if a in (\"y\",\"n\"): return a==\"y\"\n",
        "        print(\"Please type 'y' or 'n'.\")\n",
        "\n",
        "# ---------- 1) Upload CSV ----------\n",
        "print(\"Upload your QuPath measurements CSV (image filenames + centroid coordinates).\")\n",
        "up = files.upload()\n",
        "if not up: raise SystemExit(\"No file uploaded.\")\n",
        "csv_name, csv_bytes = list(up.items())[0]\n",
        "\n",
        "# ---------- 2) Settings ----------\n",
        "TOL_UM = 5.0  # overlap tolerance (µm) — change as needed\n",
        "\n",
        "# ---------- 3) Read CSV (sniff delimiter) ----------\n",
        "def read_qupath_csv(bytes_obj):\n",
        "    try:\n",
        "        return pd.read_csv(io.BytesIO(bytes_obj), sep=None, engine=\"python\")\n",
        "    except Exception:\n",
        "        return pd.read_csv(io.BytesIO(bytes_obj))\n",
        "\n",
        "df = read_qupath_csv(csv_bytes)\n",
        "\n",
        "# Use 'Image' if present, else first column as filenames\n",
        "image_col = \"Image\" if \"Image\" in df.columns else df.columns[0]\n",
        "df[\"__Image__\"] = df[image_col].astype(str).str.strip().str.casefold()\n",
        "\n",
        "# ---------- 4) Find centroid columns ----------\n",
        "def find_xy_cols(df):\n",
        "    # map lowercased header -> original\n",
        "    lc = {str(c).strip().lower(): c for c in df.columns}\n",
        "    x = (lc.get(\"centroid x µm\") or lc.get(\"centroid x [µm]\") or lc.get(\"centroid x [um]\") or\n",
        "         lc.get(\"centroid x (µm)\") or lc.get(\"xm\") or lc.get(\"x\"))\n",
        "    y = (lc.get(\"centroid y µm\") or lc.get(\"centroid y [µm]\") or lc.get(\"centroid y [um]\") or\n",
        "         lc.get(\"centroid y (µm)\") or lc.get(\"ym\") or lc.get(\"y\"))\n",
        "    if x is None or y is None:\n",
        "        raise ValueError(\"Couldn't find centroid columns (expected e.g. 'Centroid X µm' / 'Centroid Y µm').\")\n",
        "    return x, y\n",
        "\n",
        "xcol, ycol = find_xy_cols(df)\n",
        "df = df.rename(columns={xcol: \"X\", ycol: \"Y\"})\n",
        "\n",
        "# ---------- 5) STRICT channel mapping by filename ending ONLY ----------\n",
        "img = df[\"__Image__\"]\n",
        "is_dapi  = img.str.endswith(\"-dapi.ndpi\", na=False)\n",
        "is_casp3 = img.str.endswith(\"-fitc.ndpi\", na=False)  # FITC channel holds Caspase-3\n",
        "\n",
        "df[\"Channel\"] = None\n",
        "df.loc[is_dapi,  \"Channel\"] = \"DAPI\"\n",
        "df.loc[is_casp3, \"Channel\"] = \"CASP3\"\n",
        "\n",
        "DAPI  = df[df[\"Channel\"]==\"DAPI\"][[\"X\",\"Y\"]].reset_index(drop=True)\n",
        "CASP3 = df[df[\"Channel\"]==\"CASP3\"][[\"X\",\"Y\"]].reset_index(drop=True)\n",
        "\n",
        "# ---------- 6) Overlap finder (DAPI → nearest CASP3 within TOL_UM) ----------\n",
        "def pair_to_dapi(dapi_xy: np.ndarray, mark_xy: np.ndarray, tol: float):\n",
        "    if len(dapi_xy)==0 or len(mark_xy)==0:\n",
        "        return pd.DataFrame(columns=[\"X_DAPI\",\"Y_DAPI\",\"X_CASP3\",\"Y_CASP3\",\"dist_um\"])\n",
        "    tree = KDTree(mark_xy, leaf_size=40)\n",
        "    dists, idx = tree.query(dapi_xy, k=1)\n",
        "    dists = dists.ravel(); idx = idx.ravel()\n",
        "    keep = dists <= tol\n",
        "    out = pd.DataFrame({\n",
        "        \"X_DAPI\": dapi_xy[:,0],\n",
        "        \"Y_DAPI\": dapi_xy[:,1],\n",
        "        \"X_CASP3\": mark_xy[idx,0],\n",
        "        \"Y_CASP3\": mark_xy[idx,1],\n",
        "        \"dist_um\": dists\n",
        "    })\n",
        "    return out[keep].reset_index(drop=True)\n",
        "\n",
        "dapi_arr  = DAPI[[\"X\",\"Y\"]].to_numpy()\n",
        "casp3_arr = CASP3[[\"X\",\"Y\"]].to_numpy()\n",
        "\n",
        "pairs_dapi_casp3 = pair_to_dapi(dapi_arr, casp3_arr, TOL_UM)\n",
        "\n",
        "# ---------- 7) Numeric QC (no plots) ----------\n",
        "def rounded_dapi_set(pairs_df):\n",
        "    if pairs_df.empty: return set()\n",
        "    r = (pairs_df[\"X_DAPI\"].round(4).astype(str) + \",\" + pairs_df[\"Y_DAPI\"].round(4).astype(str))\n",
        "    return set(r)\n",
        "\n",
        "# Build a rounded key for *all* DAPI to find DAPI-only later\n",
        "if not DAPI.empty:\n",
        "    DAPI[\"_round_key\"] = DAPI[\"X\"].round(4).astype(str) + \",\" + DAPI[\"Y\"].round(4).astype(str)\n",
        "else:\n",
        "    DAPI[\"_round_key\"] = pd.Series(dtype=str)\n",
        "\n",
        "dapi_in_casp3 = rounded_dapi_set(pairs_dapi_casp3)\n",
        "\n",
        "# DAPI-ONLY (no CASP3 within tolerance)\n",
        "is_dapi_only = ~DAPI[\"_round_key\"].isin(dapi_in_casp3) if not DAPI.empty else pd.Series([], dtype=bool)\n",
        "DAPI_ONLY = DAPI.loc[is_dapi_only, [\"X\",\"Y\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"\\nQC summary (no plots):\")\n",
        "print(f\"  N_DAPI:                 {len(DAPI)}\")\n",
        "print(f\"  N_CASP3 (FITC channel): {len(CASP3)}\")\n",
        "print(f\"  N_DAPI+CASP3 (≤{TOL_UM} µm): {len(pairs_dapi_casp3)}\")\n",
        "print(f\"  N_DAPI_ONLY:            {len(DAPI_ONLY)}\")\n",
        "print(f\"  N_CASP3_ONLY:           {max(len(CASP3) - len(pairs_dapi_casp3), 0)}\")\n",
        "\n",
        "if not prompt_yn(\"Continue with save & download? [y/n]: \"):\n",
        "    raise SystemExit(\"Aborted by user after numeric QC.\")\n",
        "\n",
        "# ---------- 8) Build ONE CSV (pairs + DAPI-ONLY + SUMMARY) ----------\n",
        "rows = []\n",
        "if not pairs_dapi_casp3.empty:\n",
        "    a = pairs_dapi_casp3.copy()\n",
        "    a.insert(0, \"RowType\", \"PAIR_DAPI_CASP3\")\n",
        "    rows.append(a)\n",
        "\n",
        "if len(DAPI_ONLY):\n",
        "    b = DAPI_ONLY.copy()\n",
        "    b = b.rename(columns={\"X\":\"X_DAPI\",\"Y\":\"Y_DAPI\"})\n",
        "    b[\"X_CASP3\"] = np.nan\n",
        "    b[\"Y_CASP3\"] = np.nan\n",
        "    b[\"dist_um\"] = np.nan\n",
        "    b.insert(0, \"RowType\", \"DAPI_ONLY\")\n",
        "    rows.append(b)\n",
        "\n",
        "n_pairs = len(pairs_dapi_casp3)\n",
        "n_dapi_only  = len(DAPI_ONLY)\n",
        "n_casp3_only = max(len(CASP3) - n_pairs, 0)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"RowType\": [\"SUMMARY\"]*6,\n",
        "    \"Metric\": [\n",
        "        \"N_DAPI\",\"N_CASP3\",\n",
        "        \"N_DAPI_plus_CASP3\",\"N_ONLY_DAPI\",\"N_ONLY_CASP3\",\n",
        "        \"TOL_UM\"\n",
        "    ],\n",
        "    \"Value\": [\n",
        "        len(DAPI), len(CASP3),\n",
        "        n_pairs, n_dapi_only, n_casp3_only,\n",
        "        TOL_UM\n",
        "    ]\n",
        "})\n",
        "rows.append(summary)\n",
        "\n",
        "out = pd.concat(rows, ignore_index=True) if rows else summary\n",
        "out_name = \"overlap_counts_dapi_casp3.csv\"\n",
        "out.to_csv(out_name, index=False)\n",
        "files.download(out_name)\n",
        "print(f\"Done. Downloaded: {out_name}\")"
      ]
    }
  ]
}